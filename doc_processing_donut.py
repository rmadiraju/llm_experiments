# -*- coding: utf-8 -*-
"""Doc-Processing-Donut.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13Of3dG_z3obTrbEy47_1RzcbhJvjW6ff
"""

!pip install transformers==4.25.1
!pip install pytorch-lightning==1.6.4
!pip install timm==0.5.4
!pip install gradio
!pip install donut-python

import argparse
import gradio as gr
import torch
from PIL import Image

from donut import DonutModel

def process_vqa(input_img, question):
    global pretrained_model, task_prompt, task_name
    user_prompt = task_prompt.replace("{user_input}", question)
    output = pretrained_model.inference(input_img, prompt=user_prompt)["predictions"][0]
    return output

pretrained_model = DonutModel.from_pretrained("naver-clova-ix/donut-base-finetuned-docvqa")

if torch.cuda.is_available():
    pretrained_model.half()
    device = torch.device("cuda")
    pretrained_model.to(device)
else:
    pretrained_model.encoder.to(torch.bfloat16)

pretrained_model.eval()

from PIL import Image
import requests
def get_image(url):
  return Image.open(requests.get(url, stream=True).raw).convert("RGB")

task_prompt = "<s_docvqa><s_question>{user_input}</s_question><s_answer>"

url = "https://github.com/rmadiraju/llm_experiments/blob/doc-processing/data/Bookout-1.png?raw=true"
image = get_image(url)

question = "What is the vehicle vin?"
print(f"{question} \n {process_vqa(image, question)}")

question = "What is the year of the vehicle?"
print(f"{question} \n {process_vqa(image, question)}")

question = "What is the odometer reading?"
print(f"{question} \n {process_vqa(image, question)}")

question = "What is the vehicle value?"
process_vqa(image, question)

url = "https://github.com/rmadiraju/llm_experiments/blob/doc-processing/Paystub-1.jpeg?raw=true"
image = get_image(url)

# Display image if required
width, height = image.size
display(image.resize((int(0.3*width), (int(0.3*height)))))

question = "What is the net pay?"
process_vqa(image, question)

question = "What is the customer name?"
process_vqa(image, question)

question = "What is the company name?"
process_vqa(image, question)

question = "What is the pay date?"
process_vqa(image, question)

url = "https://github.com/rmadiraju/llm_experiments/blob/doc-processing/Sample-buyers-order.gif?raw=true"
image = get_image(url)

# Display image if required
width, height = image.size
display(image.resize((int(0.3*width), (int(0.3*height)))))

question = "What is the tradein vehicle?"
process_vqa(image, question)

question = "What is the odometer reading?"
process_vqa(image, question)